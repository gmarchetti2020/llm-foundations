{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10933116,"sourceType":"datasetVersion","datasetId":6798410}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Basic GPT \nImplementation of GPT from scratch in Tensorflow\n### Imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:53:55.298549Z","iopub.execute_input":"2025-03-05T21:53:55.298924Z","iopub.status.idle":"2025-03-05T21:53:59.169041Z","shell.execute_reply.started":"2025-03-05T21:53:55.298897Z","shell.execute_reply":"2025-03-05T21:53:59.167829Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"EMBEDDING_DIM = 384 # the dimension of the word embeddings\nN_HEADS = 6 #  the number of attention heads\nNUM_BLOCKS = 6 # Number of transformer blocks 12 in gpt2, 3 in gpt nano\nVALIDATION_SPLIT = 0.2 # the fraction of data to be used for validation\nSEED = 42 # the random seed for reproducibility\nSEQ_LEN = 256 # 512  # Length of training sequences, in tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:01.702318Z","iopub.execute_input":"2025-03-05T21:54:01.703048Z","iopub.status.idle":"2025-03-05T21:54:01.707951Z","shell.execute_reply.started":"2025-03-05T21:54:01.703013Z","shell.execute_reply":"2025-03-05T21:54:01.706697Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"BATCH_SIZE=128\nDROPOUT = 0.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:02.444358Z","iopub.execute_input":"2025-03-05T21:54:02.444786Z","iopub.status.idle":"2025-03-05T21:54:02.449601Z","shell.execute_reply.started":"2025-03-05T21:54:02.444755Z","shell.execute_reply":"2025-03-05T21:54:02.448008Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"MAX_ITERATIONS = 5000\nEVAL_INTERVAL = 500\nLEARNING_RATE = 3e-4\nEVAL_ITERATIONS = 200","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:05.966474Z","iopub.execute_input":"2025-03-05T21:54:05.966830Z","iopub.status.idle":"2025-03-05T21:54:05.971841Z","shell.execute_reply.started":"2025-03-05T21:54:05.966803Z","shell.execute_reply":"2025-03-05T21:54:05.970468Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Set random seed\ntf.random.set_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:07.034577Z","iopub.execute_input":"2025-03-05T21:54:07.034919Z","iopub.status.idle":"2025-03-05T21:54:07.039662Z","shell.execute_reply.started":"2025-03-05T21:54:07.034894Z","shell.execute_reply":"2025-03-05T21:54:07.038549Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Load and pre-process data\nIngest a text file","metadata":{}},{"cell_type":"code","source":"#Loading data\nwith open('/kaggle/input/coriolanus/coriolanus.txt', 'r', encoding='utf-8') as f:\n    text = f.read()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:19.880009Z","iopub.execute_input":"2025-03-05T21:54:19.880357Z","iopub.status.idle":"2025-03-05T21:54:19.893718Z","shell.execute_reply.started":"2025-03-05T21:54:19.880330Z","shell.execute_reply":"2025-03-05T21:54:19.892317Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Create a dictionary\nA simple, character-based dictionary and tokenization scheme","metadata":{}},{"cell_type":"code","source":"# Create character mappings\nchars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint (vocab_size)\nchars[:30]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:22.033445Z","iopub.execute_input":"2025-03-05T21:54:22.033902Z","iopub.status.idle":"2025-03-05T21:54:22.059031Z","shell.execute_reply.started":"2025-03-05T21:54:22.033864Z","shell.execute_reply":"2025-03-05T21:54:22.057791Z"}},"outputs":[{"name":"stdout","text":"65\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['\\n',\n ' ',\n '!',\n '$',\n '&',\n \"'\",\n ',',\n '-',\n '.',\n '3',\n ':',\n ';',\n '?',\n 'A',\n 'B',\n 'C',\n 'D',\n 'E',\n 'F',\n 'G',\n 'H',\n 'I',\n 'J',\n 'K',\n 'L',\n 'M',\n 'N',\n 'O',\n 'P',\n 'Q']"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Tokenize and de-tokenize","metadata":{}},{"cell_type":"code","source":"stoi = {ch: i for i, ch in enumerate(chars)}\nitos = {i: ch for i, ch in enumerate(chars)}\nencode = lambda s: [stoi[c] for c in s]\ndecode = lambda l: ''.join([itos[i] for i in l])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:27.454688Z","iopub.execute_input":"2025-03-05T21:54:27.455050Z","iopub.status.idle":"2025-03-05T21:54:27.460933Z","shell.execute_reply.started":"2025-03-05T21:54:27.455024Z","shell.execute_reply":"2025-03-05T21:54:27.459595Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"stoi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:54:33.199701Z","iopub.execute_input":"2025-03-05T21:54:33.200051Z","iopub.status.idle":"2025-03-05T21:54:33.208001Z","shell.execute_reply.started":"2025-03-05T21:54:33.200025Z","shell.execute_reply":"2025-03-05T21:54:33.206867Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'\\n': 0,\n ' ': 1,\n '!': 2,\n '$': 3,\n '&': 4,\n \"'\": 5,\n ',': 6,\n '-': 7,\n '.': 8,\n '3': 9,\n ':': 10,\n ';': 11,\n '?': 12,\n 'A': 13,\n 'B': 14,\n 'C': 15,\n 'D': 16,\n 'E': 17,\n 'F': 18,\n 'G': 19,\n 'H': 20,\n 'I': 21,\n 'J': 22,\n 'K': 23,\n 'L': 24,\n 'M': 25,\n 'N': 26,\n 'O': 27,\n 'P': 28,\n 'Q': 29,\n 'R': 30,\n 'S': 31,\n 'T': 32,\n 'U': 33,\n 'V': 34,\n 'W': 35,\n 'X': 36,\n 'Y': 37,\n 'Z': 38,\n 'a': 39,\n 'b': 40,\n 'c': 41,\n 'd': 42,\n 'e': 43,\n 'f': 44,\n 'g': 45,\n 'h': 46,\n 'i': 47,\n 'j': 48,\n 'k': 49,\n 'l': 50,\n 'm': 51,\n 'n': 52,\n 'o': 53,\n 'p': 54,\n 'q': 55,\n 'r': 56,\n 's': 57,\n 't': 58,\n 'u': 59,\n 'v': 60,\n 'w': 61,\n 'x': 62,\n 'y': 63,\n 'z': 64}"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### Tokenize the text and generate training / validation data sets","metadata":{}},{"cell_type":"code","source":"# Train and test splits\ndata = tf.constant(encode(text), dtype=tf.int64)\nn = int((1.0-VALIDATION_SPLIT) * len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:55:21.082780Z","iopub.execute_input":"2025-03-05T21:55:21.083183Z","iopub.status.idle":"2025-03-05T21:55:21.232017Z","shell.execute_reply.started":"2025-03-05T21:55:21.083155Z","shell.execute_reply":"2025-03-05T21:55:21.230805Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"val_data[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:55:22.145542Z","iopub.execute_input":"2025-03-05T21:55:22.145908Z","iopub.status.idle":"2025-03-05T21:55:22.154052Z","shell.execute_reply.started":"2025-03-05T21:55:22.145883Z","shell.execute_reply":"2025-03-05T21:55:22.152987Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(100,), dtype=int64, numpy=\narray([63, 53, 59,  1, 39, 56, 43,  6,  0, 32, 46, 39, 58,  1, 47, 57,  6,\n        1, 39,  1, 61, 53, 51, 39, 52, 11,  1, 47, 44,  1, 63, 53, 59,  1,\n       40, 43,  1, 51, 53, 56, 43,  6,  1, 63, 53, 59,  5, 56, 43,  1, 52,\n       53, 52, 43, 11,  0, 21, 44,  1, 63, 53, 59,  1, 40, 43,  1, 53, 52,\n       43,  6,  1, 39, 57,  1, 63, 53, 59,  1, 39, 56, 43,  1, 61, 43, 50,\n       50,  1, 43, 62, 54, 56, 43, 57, 57,  5, 42,  0, 14, 63,  1])>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Define the model","metadata":{}},{"cell_type":"code","source":"# Data loading into batches\n# the \"label\" y is the next token\ndef get_batch(split):\n    data_split = train_data if split == 'train' else val_data\n    ix = tf.random.uniform(shape=(BATCH_SIZE,), maxval=len(data_split) - SEQ_LEN, dtype=tf.int32)\n    x = tf.stack([data_split[i:i+SEQ_LEN] for i in ix])\n    y = tf.stack([data_split[i+1:i+SEQ_LEN+1] for i in ix])\n    return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:55:51.229742Z","iopub.execute_input":"2025-03-05T21:55:51.230132Z","iopub.status.idle":"2025-03-05T21:55:51.236592Z","shell.execute_reply.started":"2025-03-05T21:55:51.230104Z","shell.execute_reply":"2025-03-05T21:55:51.235249Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Calculating loss of the model\ndef estimate_loss(model):\n    out = {}\n    model.trainable = False\n    for split in ['train', 'val']:\n        losses = tf.TensorArray(tf.float32, size=EVAL_ITERATIONS)\n        for k in range(EVAL_ITERATIONS):\n            X, Y = get_batch(split)\n            logits, loss = model(X, Y)\n            losses = losses.write(k, loss)\n        out[split] = losses.stack().numpy().mean()\n    model.trainable = True\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:55:54.176300Z","iopub.execute_input":"2025-03-05T21:55:54.176730Z","iopub.status.idle":"2025-03-05T21:55:54.182807Z","shell.execute_reply.started":"2025-03-05T21:55:54.176698Z","shell.execute_reply":"2025-03-05T21:55:54.181657Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class Head(tf.keras.layers.Layer):\n    \"\"\" one head of self-attention \"\"\"\n\n    def __init__(self, head_size):\n        super(Head, self).__init__()\n        self.key = tf.keras.layers.Dense(head_size, use_bias=False)\n        self.query = tf.keras.layers.Dense(head_size, use_bias=False)\n        self.value = tf.keras.layers.Dense(head_size, use_bias=False)\n\n        tril = tf.linalg.band_part(tf.ones((SEQ_LEN, SEQ_LEN)), -1, 0)\n        self.tril = tf.constant(tril)\n\n        self.dropout = tf.keras.layers.Dropout(DROPOUT)\n\n    def call(self, x):\n        # input of size (batch, time-step, channels)\n        # output of size (batch, time-step, head size)\n        B, T, C = x.shape\n        k = self.key(x)   # (B, T, hs)\n        q = self.query(x) # (B, T, hs)\n\n        # compute attention scores \n        wei = tf.matmul(q, tf.transpose(k, perm=[0, 2, 1])) * tf.math.rsqrt(tf.cast(k.shape[-1], tf.float32))  # (B, T, T)\n        wei = tf.where(self.tril[:T, :T] == 0, float('-inf'), wei)  # (B, T, T)\n        wei = tf.nn.softmax(wei, axis=-1)  # (B, T, T)\n        wei = self.dropout(wei)\n\n        # perform the weighted aggregation of the values\n        v = self.value(x)  # (B, T, hs)\n        out = tf.matmul(wei, v)  # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:56:01.719385Z","iopub.execute_input":"2025-03-05T21:56:01.719815Z","iopub.status.idle":"2025-03-05T21:56:01.728863Z","shell.execute_reply.started":"2025-03-05T21:56:01.719785Z","shell.execute_reply":"2025-03-05T21:56:01.727607Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class MultiHeadAttention(tf.keras.layers.Layer):\n    \"\"\" multiple heads of self-attention in parallel \"\"\"\n\n    def __init__(self, num_heads, head_size):\n        super(MultiHeadAttention, self).__init__()\n        self.heads = [Head(head_size) for _ in range(num_heads)]\n        self.proj = tf.keras.layers.Dense(EMBEDDING_DIM)\n        self.dropout = tf.keras.layers.Dropout(DROPOUT)\n\n    def call(self, x):\n        out = tf.concat([h(x) for h in self.heads], axis=-1)\n        out = self.dropout(self.proj(out))\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:56:04.590640Z","iopub.execute_input":"2025-03-05T21:56:04.590990Z","iopub.status.idle":"2025-03-05T21:56:04.597832Z","shell.execute_reply.started":"2025-03-05T21:56:04.590963Z","shell.execute_reply":"2025-03-05T21:56:04.596463Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class FeedForward(tf.keras.layers.Layer):\n    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n\n    def __init__(self, n_embd):\n        super(FeedForward, self).__init__()\n        self.net = tf.keras.Sequential([\n            tf.keras.layers.Dense(4 * n_embd),\n            tf.keras.layers.ReLU(),\n            tf.keras.layers.Dense(n_embd),\n            tf.keras.layers.Dropout(DROPOUT),\n        ])\n\n    def call(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:56:07.290391Z","iopub.execute_input":"2025-03-05T21:56:07.291026Z","iopub.status.idle":"2025-03-05T21:56:07.297346Z","shell.execute_reply.started":"2025-03-05T21:56:07.290986Z","shell.execute_reply":"2025-03-05T21:56:07.295939Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class Block(tf.keras.layers.Layer):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        super(Block, self).__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedForward(n_embd)\n        self.ln1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.ln2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n\n    def call(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:56:09.216836Z","iopub.execute_input":"2025-03-05T21:56:09.217172Z","iopub.status.idle":"2025-03-05T21:56:09.223641Z","shell.execute_reply.started":"2025-03-05T21:56:09.217147Z","shell.execute_reply":"2025-03-05T21:56:09.222351Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class GPTLanguageModel(tf.keras.Model):\n\n    def __init__(self):\n        super(GPTLanguageModel, self).__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIM)\n        self.position_embedding_table = tf.keras.layers.Embedding(SEQ_LEN, EMBEDDING_DIM)\n        self.blocks = tf.keras.Sequential([Block(EMBEDDING_DIM, n_head=N_HEADS) for _ in range(NUM_BLOCKS)])\n        self.ln_f = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n        self.lm_head = tf.keras.layers.Dense(vocab_size, kernel_initializer='normal', bias_initializer='zeros')\n\n    def call(self, idx, targets=None):\n        B, T = idx.shape\n\n        # idx and targets are both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n        pos_emb = self.position_embedding_table(tf.range(T, dtype=tf.float32))  # (T,C)\n        x = tok_emb + pos_emb  # (B,T,C)\n        x = self.blocks(x)  # (B,T,C)\n        x = self.ln_f(x)  # (B,T,C)\n        logits = self.lm_head(x)  # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = tf.reshape(logits, (B * T, C))\n            targets = tf.reshape(targets, (B * T,))\n            loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(targets, logits)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last SEQ_LEN tokens\n            idx_cond = idx[:, -SEQ_LEN:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :]  # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = tf.nn.softmax(logits, axis=-1)  # (B, C)\n            # sample from the distribution\n            idx_next = tf.random.categorical(tf.math.log(probs), num_samples=1, dtype=tf.int64)  # (B, 1)\n            # append sampled index to the running sequence\n            idx = tf.concat([idx, idx_next], axis=1)  # (B, T+1)\n        return idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:56:12.321725Z","iopub.execute_input":"2025-03-05T21:56:12.322076Z","iopub.status.idle":"2025-03-05T21:56:12.331936Z","shell.execute_reply.started":"2025-03-05T21:56:12.322049Z","shell.execute_reply":"2025-03-05T21:56:12.330553Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Initializing model with pre-trained weights. Use this if you don't want to re-train the model.\n#model = GPTLanguageModel()\n#dummy_input = tf.constant([[0]], dtype=tf.int32)  # Example input, adjust shape as needed\n#model(dummy_input)\n#model.load_weights('/kaggle/working/gpt_model_basic.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:57:17.168966Z","iopub.execute_input":"2025-03-05T21:57:17.169454Z","iopub.status.idle":"2025-03-05T21:57:17.173923Z","shell.execute_reply.started":"2025-03-05T21:57:17.169402Z","shell.execute_reply":"2025-03-05T21:57:17.172723Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"## Train the model","metadata":{}},{"cell_type":"code","source":"#Training the model. GPU is recommended for training.\n\nmodel = GPTLanguageModel()\noptimizer = tf.keras.optimizers.AdamW(LEARNING_RATE)\n\nfor iter in range(MAX_ITERATIONS):\n\n    # sample a batch of data\n    xb, yb = get_batch('train')\n\n    # evaluate the loss\n    with tf.GradientTape() as tape:\n        logits, loss = model(xb, yb)\n\n    # every once in a while evaluate the loss on train and val sets \n    # MUST happen after tape update\n    if iter % EVAL_INTERVAL == 0 or iter == MAX_ITERATIONS - 1:\n        losses = estimate_loss(model)\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T21:57:18.326942Z","iopub.execute_input":"2025-03-05T21:57:18.327327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generation \nwith pre-trained model","metadata":{}},{"cell_type":"code","source":"# generate from the model\ncontext = tf.zeros((1, 1), dtype=tf.int64)\ngenerated_sequence = model.generate(context, max_new_tokens=500).numpy()\nprint(decode(generated_sequence[0]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"model.save_weights('/kaggle/working/gpt_model_basic.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}